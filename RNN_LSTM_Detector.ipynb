{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "RNN_LSTM_Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RvgQTumJYQO8"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idoFinder/RNN_LSTM_API_CALLS/blob/master/RNN_LSTM_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:17:35.118725Z",
          "start_time": "2020-05-15T12:17:35.105725Z"
        },
        "id": "ATAoBNAOYQOE",
        "colab_type": "code",
        "outputId": "39e54753-1ca9-4490-875c-ecfd9f6caf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential, load_model ,Model\n",
        "from keras.layers import Dense, LSTM,Embedding,GlobalMaxPooling1D,Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score, confusion_matrix, accuracy_score, recall_score,plot_confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing, metrics\n",
        "from itertools import groupby\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98EJvMiXYb8P",
        "colab_type": "code",
        "outputId": "674716f2-67c2-4618-b895-5fadebcb939b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hM383LbYf7h",
        "colab_type": "code",
        "outputId": "054699dc-8141-4a62-fade-11c6c7ca93b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMpDMrim0rDY",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "1_DDCKXKYQOK",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "9q75_tgAYQOK",
        "colab_type": "text"
      },
      "source": [
        "### Read raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T20:14:53.413431Z",
          "start_time": "2020-05-14T19:22:12.518448Z"
        },
        "hidden": true,
        "id": "jeWKDRpMYQOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_raw_parquets(path):\n",
        "  all_data = pd.DataFrame(columns=['file_name','API_sequence','class'])\n",
        "  for idx, batch_path in enumerate(os.listdir(path)):\n",
        "      full_path = '{}/{}'.format(path,batch_path)\n",
        "      batch = pd.read_parquet(full_path)\n",
        "      files = batch['file_name'].unique()\n",
        "      new_records = []\n",
        "      for file in files:\n",
        "          sub_df = batch[batch['file_name']==file].sort_values(['normalized_time'])\n",
        "          file_class = sub_df.iloc[0]['class']\n",
        "          new_record = {'file_name':file,'API_sequence':sub_df['API'].values,'class':file_class}\n",
        "          new_records.append(new_record)\n",
        "      all_data = all_data.append(new_records, ignore_index=True)\n",
        "      print('batch',idx+1, ' loaded')\n",
        "    \n",
        "  return all_data\n",
        "\n",
        "\n",
        "\n",
        "def get_classes_distribution_df(df):\n",
        "    num_of_benign = df[df['class'] == 'benign'].shape[0]\n",
        "    num_of_malware = df[df['class'] == 'malicious'].shape[0]\n",
        "    total = num_of_benign + num_of_malware\n",
        "    benign_perc = round((num_of_benign / total) * 100, 2)\n",
        "    malware_perc = round((num_of_malware / total) * 100, 2)\n",
        "    res_str = 'Benign:{} ({}%) | Malicious:{} ({}%)'.format(num_of_benign, benign_perc, num_of_malware, malware_perc)\n",
        "    return res_str\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "tIwTNMdJYQOV",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning + creating API corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:36:50.009079Z",
          "start_time": "2020-05-15T12:36:50.002119Z"
        },
        "hidden": true,
        "id": "7SwUUwYNYQOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_repitations(sequence):\n",
        "    new_sequence = [x[0] for x in groupby(sequence)]\n",
        "    return new_sequence\n",
        "\n",
        "\n",
        "def data_cleaning(sequence_MIN_length,all_data):\n",
        "  # remove repitation in all data\n",
        "  all_data['API_sequence'] =all_data.apply(lambda x: remove_repitations(x['API_sequence']), axis=1)\n",
        "\n",
        "  # remove sequences shorter then sequence_MIN_length\n",
        "  print('Remove files with short sequence')\n",
        "  print('files before:',all_data.shape[0])\n",
        "  to_drop = []\n",
        "  for file in all_data['file_name']:\n",
        "      if len(all_data[all_data['file_name']==file].API_sequence.values[0]) < sequence_MIN_length:\n",
        "          to_drop.append(file)\n",
        "  all_data = all_data[~all_data['file_name'].isin(to_drop)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  all_data = all_data.reset_index(drop=True)\n",
        "  return all_data\n",
        "\n",
        "\n",
        "def use_spesific_files(dataset_path,all_data):\n",
        "  balanced_csv = pd.read_csv(dataset_path)\n",
        "  print('files before:',all_data.shape[0])\n",
        "  all_data = all_data[all_data['file_name'].isin(balanced_csv['file_name'].values)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  all_data = all_data.reset_index(drop=True)\n",
        "  return all_data\n",
        "\n",
        "# create API calls corpus\n",
        "def create_API_corpus(all_data):\n",
        "  API_corpus = []\n",
        "  for file in all_data['file_name']:\n",
        "      seq = all_data[all_data['file_name']==file].API_sequence.values[0]\n",
        "      API_corpus.extend(set(seq))\n",
        "  API_corpus = list(set(API_corpus))\n",
        "  print('API_corpus:',len(API_corpus))\n",
        "  return API_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "T19fW4K6YQOk",
        "colab_type": "text"
      },
      "source": [
        "## Representation Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "NJoeddnWYQOd",
        "colab_type": "text"
      },
      "source": [
        "### Functions: one-hot-encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:47.658061Z",
          "start_time": "2020-05-15T15:08:47.630084Z"
        },
        "hidden": true,
        "id": "XEztAvokYQOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_API_to_vector(Unique_API_calls,API):\n",
        "    if API != 0:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "        vec[Unique_API_calls.index(API)] = 1.0\n",
        "    else:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "    return list(vec)\n",
        "\n",
        "\n",
        "def create_sequence_n_nextWord_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    sequences = []\n",
        "    next_words = []\n",
        "    for seq in vectorized_data:\n",
        "        sequences.append(seq[:-1])\n",
        "        next_words.append(seq[len(seq)-1])\n",
        "    \n",
        "    return np.array(sequences),np.array(next_words)\n",
        "\n",
        "\n",
        "def create_sequence_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    return np.array(vectorized_data)\n",
        "\n",
        "\n",
        "def pruning_n_padding(seq,sequence_MAX_length):\n",
        "    final_seq = []\n",
        "    if len(seq) < sequence_MAX_length+1:\n",
        "        gap = (sequence_MAX_length) - len(seq)\n",
        "        zeros = [0] * gap\n",
        "        final_seq = list(zeros) + list(seq)\n",
        "    \n",
        "    elif len(seq) == sequence_MAX_length:\n",
        "        final_seq = list(seq)\n",
        "    \n",
        "    else:\n",
        "        final_seq = seq[:sequence_MAX_length]\n",
        "    return final_seq\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "BTyk8CV_YQOl",
        "colab_type": "text"
      },
      "source": [
        "### Predict next API call "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "pGte-d5ZYQOl",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:38:01.334154Z",
          "start_time": "2020-05-15T12:38:00.927149Z"
        },
        "hidden": true,
        "id": "2zgKHUCeYQOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_nextWord(data,sequence_MAX_length):\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length + next API as a label\n",
        "  LSTM_train_seq =  data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "  # create sequences and nextWords\n",
        "  train_vectorized_seq, train_vectorized_nextWord = create_sequence_n_nextWord_one_hot(LSTM_train_seq)\n",
        "\n",
        "  # print('train_vectorized_seq:',train_vectorized_seq.shape, ' train_vectorized_nextWord:',train_vectorized_nextWord.shape)\n",
        "\n",
        "  return train_vectorized_seq, train_vectorized_nextWord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "jpOTUQFlYQOq",
        "colab_type": "text"
      },
      "source": [
        "#### Architecture 1:###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "wz0mDQ9-YQOr",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:39:15.989070Z",
          "start_time": "2020-05-15T12:39:05.000660Z"
        },
        "hidden": true,
        "id": "6_SiUrHUYQOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_nextWord_arch_1(output_dim,input_seq_size,input_time_dim,nb_units,dropout):\n",
        "  seed_value= 10\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  # build the model\n",
        "  model_1 = Sequential()\n",
        "  model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout ,return_sequences=True))\n",
        "  model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout,return_sequences=False))\n",
        "  model_1.add(Dense(output_dim,activation='softmax'))\n",
        "  model_1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  # print(model_1.summary())\n",
        "  return model_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "rWtO0iVHYQOx",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.756860Z",
          "start_time": "2020-05-15T12:36:46.294Z"
        },
        "hidden": true,
        "id": "p69VSdGBYQOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_LSTM_nextWord(model,x_test,y_test):\n",
        "  predictions = model.predict(x_test)\n",
        "  decoded_preds = []\n",
        "  for idx in range(predictions.shape[0]):\n",
        "      decoded = API_corpus[np.argmax(predictions[idx])]\n",
        "      decoded_preds.append(decoded)\n",
        "      \n",
        "  decoded_true = []\n",
        "  for idx in range(y_test.shape[0]):\n",
        "      decoded = API_corpus[np.argmax(x_test[idx])]\n",
        "      decoded_true.append(decoded)\n",
        "\n",
        "  print('predicted corpus:', str(set(decoded_preds)))\n",
        "\n",
        "  correct = 0\n",
        "  for idx in range(len(decoded_preds)):\n",
        "      if decoded_preds[idx] == decoded_true[idx]:\n",
        "          correct += 1\n",
        "          \n",
        "  print('LSTM representation accuracy:', round(correct/len(decoded_preds),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "RvgQTumJYQO8",
        "colab_type": "text"
      },
      "source": [
        "#### Architecture 2: (Optional)###\n",
        "- Input: integers\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Mk6Gtc2sYQO8",
        "colab_type": "text"
      },
      "source": [
        "#### Architecture 3: (Optional)###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 1 LSTM layers (return_sequence=True)+ Dense using softmax\n",
        "- Feed the model with the next API for each input cell (offset of the APIs)\n",
        "- Next, remove the last Dense layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "FF650hUBYQO-",
        "colab_type": "text"
      },
      "source": [
        "### Predict final label (0/1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "5QaoG-gMYQO_",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:40.423935Z",
          "start_time": "2020-05-15T15:08:40.370936Z"
        },
        "hidden": true,
        "id": "PAGtmh8OYQO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_finalLabel(x_data, y_data,sequence_MAX_length):\n",
        "  # print('Preparing data - final Label LSTM')\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length\n",
        "  LSTM_train_seq =  x_data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "\n",
        "  # convert API sequence to one-hot-encoding vectors\n",
        "  train_vectorized_seq = create_sequence_one_hot(LSTM_train_seq)\n",
        "\n",
        "  # convert class to 0 and 1\n",
        "  rep_train_labels = np.array(y_data.apply(lambda x: 1 if x == 'malicious' else 0).values,dtype=np.float32)\n",
        "\n",
        "  # print('x_data shape:',train_vectorized_seq.shape, ' y_data shape:',rep_train_labels.shape)\n",
        "\n",
        "  return np.array(train_vectorized_seq), np.array(rep_train_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "oF6TPDGUYQPE",
        "colab_type": "text"
      },
      "source": [
        "#### Architecture 1:###\n",
        "- Train model with 2 LSTM layers + Dense using sigmoid\n",
        "- Predict the class using the second layer last-cell \n",
        "- Next, remove the second LSTM layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "dxTRoY6hYQPE",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:33:56.855816Z",
          "start_time": "2020-05-15T15:33:55.003172Z"
        },
        "hidden": true,
        "id": "fgUpIJcWYQPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_finalLabel_arch_1(input_seq_size,input_time_dim,nb_units,dropout):\n",
        "  # Seed value\n",
        "  seed_value= 10\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  print('Bulding LSTM model - final Label (arch 1)')\n",
        "\n",
        "  # build the model\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout ,return_sequences=True))\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout,return_sequences=False))\n",
        "  model_2.add(Dense(1, activation='sigmoid'))\n",
        "  model_2.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  # print(model_2.summary())\n",
        "  return model_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9IiF9WS7YQPL",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:00.378396Z",
          "start_time": "2020-05-15T16:28:16.113640Z"
        },
        "hidden": true,
        "id": "cJoSHea_YQPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_LSTM_finalLabel(model,x_test,y_test):\n",
        "\n",
        "  predictions = model.predict(x_test)\n",
        "  final_preds = []\n",
        "  for pred in predictions:\n",
        "      if pred > 0.5:\n",
        "          final_preds.append(1.0)\n",
        "      else:\n",
        "          final_preds.append(0.0)\n",
        "          \n",
        "  correct = 0\n",
        "  for idx, pred in enumerate(final_preds):\n",
        "      if final_preds[idx] == y_test[idx]:                            \n",
        "          correct+=1\n",
        "  print('LSTM representation accuracy:',round(correct/len(final_preds),4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OKq1JUEYQPP",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction - from LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BL7ZJpYQPR",
        "colab_type": "text"
      },
      "source": [
        "### Extract features using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:21.909349Z",
          "start_time": "2020-05-15T16:29:21.891314Z"
        },
        "id": "Lxn7loXAYQPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_vector_maxPool_n_lastCell(trained_model, sequence_data):\n",
        "  # Seed value\n",
        "  seed_value= 10\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model.add(layer)\n",
        "\n",
        "  preds = new_model.predict(sequence_data)\n",
        "\n",
        "  # save all the last lstm cell outputs\n",
        "  last_cell_outputs = []\n",
        "  for file in preds:\n",
        "      last_cell_outputs.append(file[-1]) \n",
        "\n",
        "  del preds\n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model_max_pooling = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model_max_pooling.add(layer)\n",
        "\n",
        "  # add softmax + max pooling layer\n",
        "  new_model_max_pooling.add(GlobalMaxPooling1D())\n",
        "  max_pooling_vectors = new_model_max_pooling.predict(sequence_data)\n",
        "\n",
        "  \n",
        "  # Creating the representation vectors:\n",
        "  # concatenating the max-pooling with the last output\n",
        "  final_representation = []\n",
        "  for idx,max_pool in enumerate(max_pooling_vectors):\n",
        "      new_vector = list(max_pool) + list(last_cell_outputs[idx])\n",
        "      final_representation.append(new_vector)\n",
        "  final_representation = np.array(final_representation,dtype=np.float32)\n",
        "  # print('final shape:', str(final_representation.shape) )\n",
        "  del max_pooling_vectors\n",
        "  \n",
        "  return final_representation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:48:30.977421Z",
          "start_time": "2020-05-15T16:30:43.348085Z"
        },
        "id": "e_cy17fKYQPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_feature_vector(trained_model,x_data,y_data,one_hot_encoding,sequence_MAX_length):\n",
        "  # pruning the sequences to match sequence_MAX_length \n",
        "  rep_train_seq =  x_data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "\n",
        "  # convert class to 0 and 1\n",
        "  labels = y_data.apply(lambda x: 1 if x == 'malicious' else 0).values\n",
        "\n",
        "  if one_hot_encoding:\n",
        "    # print('creating one-hot-encoding')\n",
        "    # create sequences (one-hote encoding format) *we dont use the nextWord here\n",
        "    train_vectorized_seq = create_sequence_one_hot(rep_train_seq)\n",
        "    del rep_train_seq\n",
        "    # print('Creating feature vectors')\n",
        "    train_feature_vector = feature_vector_maxPool_n_lastCell(trained_model, train_vectorized_seq)\n",
        "    del train_vectorized_seq\n",
        "\n",
        "  return np.array(train_feature_vector), np.array(labels, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzUU3oYDYQPV",
        "colab_type": "text"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T11:43:02.671328Z",
          "start_time": "2020-05-15T11:43:02.645329Z"
        },
        "hidden": true,
        "id": "TayLH2KMYQPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_metrics(conf_matrix, Y_proba, Y_test):\n",
        "    AUC = roc_auc_score(Y_test, Y_proba)\n",
        "\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "\n",
        "    TPR = TP / (TP + FN)\n",
        "    FPR = FP / (FP + TN)\n",
        "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
        "    Precision = TP / (TP + FP)\n",
        "    F1_score = 2 * ((Precision * TPR) / (Precision + TPR))\n",
        "\n",
        "    metrics_dict = {\n",
        "        'TPR': round(TPR, 2),\n",
        "        'FPR': round(FPR, 2),\n",
        "        'ACC': round(ACC, 2),\n",
        "        'Precision': round(Precision, 2),\n",
        "        'F1_score': round(F1_score, 2),\n",
        "        'AUC': round(AUC, 4),\n",
        "    }\n",
        "\n",
        "    return metrics_dict\n",
        "\n",
        "\n",
        "def convert_class_to_binary(label):\n",
        "    if label == 'malicious':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "def get_predictions(Y_proba, threshold):\n",
        "    Y_pred_final = []\n",
        "    for p in Y_proba:\n",
        "        if p >= threshold:\n",
        "            Y_pred_final.append(1.0)\n",
        "        else:\n",
        "            Y_pred_final.append(0.0)\n",
        "\n",
        "    return np.array(Y_pred_final)\n",
        "\n",
        "def LR_fit(x_train, y_train, max_iter):\n",
        "\n",
        "  # normalizing the data\n",
        "  x_train_final = StandardScaler().fit_transform(x_train)\n",
        "  # init model + fit\n",
        "  LR = LogisticRegression(max_iter=max_iter)\n",
        "  LR.fit(x_train_final, y_train)\n",
        "\n",
        "  return LR\n",
        "\n",
        "\n",
        "def LR_predict(model,x_test):\n",
        "  # Get probability for each class\n",
        "  x_test_final = StandardScaler().fit_transform(x_test)\n",
        "  y_proba = model.predict_proba(x_test_final)[:, 1]\n",
        "  # convert probabilities into predictions based on the threshold\n",
        "  y_pred = get_predictions(y_proba, threshold=0.5)\n",
        "\n",
        "  return y_pred,y_proba\n",
        "\n",
        "def LSTM_predict(model, x_test):\n",
        "  # Get probability for each class\n",
        "  y_proba = model.predict(x_test)\n",
        "  # convert probabilities into predictions based on the threshold\n",
        "  y_pred = get_predictions(y_proba, threshold=0.5)\n",
        "\n",
        "  return y_pred,y_proba\n",
        "\n",
        "\n",
        "def print_final_results(y_test,folds_TPR,folds_FPR,folds_ACC,folds_Precision,folds_F1_score,folds_AUC):\n",
        "  print('\\nFinal Results: {} samples'.format(y_test.shape[0]))\n",
        "  print('TPR:', round(np.mean(folds_TPR),4))\n",
        "  print('FPR:', round(np.mean(folds_FPR),4))\n",
        "  print('ACC:', round(np.mean(folds_ACC),4))\n",
        "  print('Precision:', round(np.mean(folds_Precision),4))\n",
        "  print('F1_score:', round(np.mean(folds_F1_score),4))\n",
        "  print('AUC:', round(np.mean(folds_AUC),4))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOfXEsTNzO7v",
        "colab_type": "text"
      },
      "source": [
        "# Main\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFangIGCDjl3",
        "colab_type": "text"
      },
      "source": [
        "## Load Train Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiiHQYkyDb2V",
        "colab_type": "code",
        "outputId": "92408a4f-0276-469e-9efb-8127d7b1f4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "all_data = pd.read_pickle('/content/drive/My Drive/Thesis/RNN_LSTM/data_for_LSTM.pkl')\n",
        "\n",
        "# Clean data (remove short sequence & remove duplications)\n",
        "sequence_MIN_length = 15 # (Pascano, 2015)\n",
        "all_data = data_cleaning(sequence_MIN_length,all_data)\n",
        "\n",
        "# use file from other experiments\n",
        "dataset_name = '1_Balanced_Frequencies_first1000sec_minAPI_15_minRunTime_0_withYara_No.csv'\n",
        "dataset_name = '0_Balanced_Frequencies_first1000sec_minAPI_0_minRunTime_0_withYara_No.csv'\n",
        "folder_path = '/content/drive/My Drive/Thesis/RNN_LSTM/balaned_datasets'\n",
        "full_path = '{}/{}'.format(folder_path,dataset_name)\n",
        "all_data = use_spesific_files(full_path,all_data)\n",
        "\n",
        "API_corpus = create_API_corpus(all_data)\n",
        "\n",
        "all_data_distribuation = get_classes_distribution_df(all_data)\n",
        "print(all_data_distribuation)\n",
        "\n",
        "\n",
        "train_sequences = all_data['API_sequence']\n",
        "train_labels = all_data['class']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove files with short sequence\n",
            "files before: 7156\n",
            "files after: 6166\n",
            "files before: 6166\n",
            "files after: 4596\n",
            "API_corpus: 302\n",
            "Benign:2277 (49.54%) | Malicious:2319 (50.46%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezy9_3Zd4JyJ",
        "colab_type": "text"
      },
      "source": [
        "## Set Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkP861Qx4Jh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare data for representation model (Optional)\n",
        "LSTM_train_seq_MAX_length = 50 # (Athiwaratkun, 2017)\n",
        "LSTM_train_seq_MAX_length = 100 # (Pascanu, 2015)\n",
        "LSTM_train_seq_MAX_length = 100 # (Pascanu, 2015)\n",
        "\n",
        "# LSTM learning params\n",
        "output_dim = len(API_corpus)\n",
        "input_seq_size = len(API_corpus)\n",
        "input_time_dim = None\n",
        "nb_units = 1500 # (pascanu 2015, Agrawal 2018, Athiwaratkun 2017)\n",
        "nb_units = 100 # (Zhang 2020)\n",
        "dropout = 0.1\n",
        "epochs = 5\n",
        "# nb_folds = 10\n",
        "\n",
        "representation_learning = False\n",
        "\n",
        "# Classification params\n",
        "classification_seq_MAX_length = 200 #(Agrawal 2018 , Athiwaratkun 2017)\n",
        "one_hot_encoding = True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIMbwhiHyxQQ",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR2Iu0y-yxCi",
        "colab_type": "code",
        "outputId": "cbf71677-d4bb-4692-ddfe-f290bac3b6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# prepare data for LSTM training with the final label (0/1)\n",
        "x_train,y_train = prepare_data_finalLabel(train_sequences,train_labels,LSTM_train_seq_MAX_length)\n",
        "\n",
        "\n",
        "# create the LSTM model\n",
        "LSTM_model = LSTM_finalLabel_arch_1(input_seq_size,\n",
        "                                    input_time_dim,\n",
        "                                    nb_units,\n",
        "                                    dropout)\n",
        "\n",
        "# train model on training data\n",
        "LSTM_model.fit(x_train,y_train, epochs=epochs)\n",
        "\n",
        "LSTM_model.save('/content/drive/My Drive/Thesis/RNN_LSTM/Trained_LSTM_finalLabel_arch_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4596/4596 [==============================] - 50s 11ms/step - loss: 0.4852 - accuracy: 0.7846\n",
            "Epoch 2/5\n",
            "4596/4596 [==============================] - 48s 10ms/step - loss: 0.3719 - accuracy: 0.8527\n",
            "Epoch 3/5\n",
            "4596/4596 [==============================] - 48s 10ms/step - loss: 0.3291 - accuracy: 0.8747\n",
            "Epoch 4/5\n",
            "4596/4596 [==============================] - 48s 10ms/step - loss: 0.3021 - accuracy: 0.8864\n",
            "Epoch 5/5\n",
            "4596/4596 [==============================] - 49s 11ms/step - loss: 0.3001 - accuracy: 0.8893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeOvEPcH3CKp",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD0AxRVw3Bq0",
        "colab_type": "code",
        "outputId": "cfa4a66e-cfc1-4a9a-f417-a6353bf28f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_data = load_raw_parquets('/content/drive/My Drive/Thesis/RNN_LSTM/Detection_data/APT_raw_parquets')\n",
        "test_data = data_cleaning(1,test_data)\n",
        "\n",
        "test_sequences = test_data['API_sequence']\n",
        "test_labels = test_data['class']\n",
        "\n",
        "\n",
        "# prepare data for LSTM training with the final label (0/1)\n",
        "x_test, y_test = prepare_data_finalLabel(test_sequences,test_labels,LSTM_train_seq_MAX_length)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 1  loaded\n",
            "Remove files with short sequence\n",
            "files before: 6\n",
            "files after: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1DS12Vy3I-x",
        "colab_type": "text"
      },
      "source": [
        "## Detection - Only LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzDsnpxWy19w",
        "colab_type": "code",
        "outputId": "49754a0c-699d-4153-be46-94a41adf878e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "LSTM_model_trained = load_model('/content/drive/My Drive/Thesis/RNN_LSTM/Trained_LSTM_finalLabel_arch_1.h5')\n",
        "\n",
        "\n",
        "y_preds,y_proba = LSTM_predict(LSTM_model_trained,x_test)\n",
        "y_proba"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99752945],\n",
              "       [0.75231177],\n",
              "       [0.99350834],\n",
              "       [0.7061012 ],\n",
              "       [0.22993211],\n",
              "       [0.75231177]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7IvO1z8ahy",
        "colab_type": "text"
      },
      "source": [
        "## Detection - LSTM + LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kAPEf6Prb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_model_trained = load_model('/content/drive/My Drive/Thesis/RNN_LSTM/Trained_LSTM_finalLabel_arch_1.h5')\n",
        "\n",
        "# create train feature vector - feature extraction\n",
        "x_train_rep, y_train_rep = final_feature_vector(LSTM_model_trained,\n",
        "                                    train_sequences,\n",
        "                                    train_labels,\n",
        "                                    one_hot_encoding,\n",
        "                                    classification_seq_MAX_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYQ7Jucb8aRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# create train feature vector - feature extraction\n",
        "x_train_rep, y_train_rep = final_feature_vector(LSTM_model_trained,\n",
        "                                    train_sequences,\n",
        "                                    train_labels,\n",
        "                                    one_hot_encoding,\n",
        "                                    classification_seq_MAX_length)\n",
        "\n",
        "# create test feature vector - feature extraction\n",
        "x_test_rep, y_test_rep = final_feature_vector(LSTM_model_trained,\n",
        "                                    test_sequences,\n",
        "                                    test_labels,\n",
        "                                    one_hot_encoding,\n",
        "                                    classification_seq_MAX_length)\n",
        "\n",
        "# train classifier\n",
        "LR_classifier = LR_fit(x_train_rep, y_train_rep, max_iter=1000)\n",
        "\n",
        "# predict \n",
        "y_preds,y_proba = LR_predict(LR_classifier,x_test_rep)\n",
        "y_proba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_2tygDfDebw",
        "colab_type": "text"
      },
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8CtypfMfE8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame(columns=['file_name','true_class','LSTM'])\n",
        "\n",
        "for idx, f in enumerate(test_data['file_name'].unique()):\n",
        "  f_df = test_data[test_data['file_name'] == f]\n",
        "  file_name = f_df['file_name'].values[0]\n",
        "  file_class = int(y_test[idx])\n",
        "  prediction = y_proba[idx][0]\n",
        "\n",
        "  new_record = {\n",
        "      'file_name':file_name,'true_class':file_class,'LSTM':prediction\n",
        "  }\n",
        "\n",
        "  results = results.append(new_record, ignore_index=True)\n",
        "\n",
        "results.to_csv('/content/drive/My Drive/Thesis/RNN_LSTM/LSTM_results.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}