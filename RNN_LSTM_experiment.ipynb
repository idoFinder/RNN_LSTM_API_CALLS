{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "RNN_LSTM_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NJoeddnWYQOd",
        "pGte-d5ZYQOl",
        "jpOTUQFlYQOq",
        "RvgQTumJYQO8",
        "5QaoG-gMYQO_",
        "oF6TPDGUYQPE",
        "0ay7iywNYQPP",
        "C8BL7ZJpYQPR",
        "HdCT0a9bYQPV",
        "f7SMtghsYQPX",
        "8YJxffN2YQPY"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idoFinder/RNN_LSTM_API_CALLS/blob/master/RNN_LSTM_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:17:35.118725Z",
          "start_time": "2020-05-15T12:17:35.105725Z"
        },
        "id": "ATAoBNAOYQOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, load_model ,Model\n",
        "from keras.layers import Dense, LSTM,Embedding,GlobalMaxPooling1D,Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score, confusion_matrix, accuracy_score, recall_score,plot_confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing, metrics\n",
        "from itertools import groupby\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98EJvMiXYb8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e4f2d8-b497-43e7-8ca6-4512afe2f3c0"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hM383LbYf7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "10260004-3015-493c-e677-f4e85a9ce40a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "1_DDCKXKYQOK",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "9q75_tgAYQOK",
        "colab_type": "text"
      },
      "source": [
        "## Read raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T20:14:53.413431Z",
          "start_time": "2020-05-14T19:22:12.518448Z"
        },
        "hidden": true,
        "id": "jeWKDRpMYQOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_raw_parquets(benign_path, malware_path):\n",
        "  # load benign parquets\n",
        "  all_data = pd.DataFrame(columns=['file_name','API_sequence','class'])\n",
        "  for idx, batch_path in enumerate(os.listdir(benign_path)):\n",
        "      path = '{}/{}'.format(folder_path,batch_path)\n",
        "      batch = pd.read_parquet(path)\n",
        "      files = batch['file_name'].unique()\n",
        "      new_records = []\n",
        "      for file in files:\n",
        "          sub_df = batch[batch['file_name']==file].sort_values(['normalized_time'])\n",
        "          new_record = {'file_name':file,'API_sequence':sub_df['API'].values,'class':'benign'}\n",
        "          new_records.append(new_record)\n",
        "      all_data = all_data.append(new_records, ignore_index=True)\n",
        "      print('batch',idx+1, ' loaded')\n",
        "      \n",
        "  # load malicious parquets\n",
        "  for idx, batch_path in enumerate(os.listdir(malware_path)):\n",
        "      path = '{}/{}'.format(folder_path,batch_path)\n",
        "      batch = pd.read_parquet(path)\n",
        "      files = batch['file_name'].unique()\n",
        "      new_records = []\n",
        "      for file in files:\n",
        "          sub_df = batch[batch['file_name']==file].sort_values(['normalized_time'])\n",
        "          new_record = {'file_name':file,'API_sequence':sub_df['API'].values,'class':'malicious'}\n",
        "          new_records.append(new_record)\n",
        "      all_data = all_data.append(new_records, ignore_index=True)\n",
        "      print('batch',idx+1, ' loaded')\n",
        "    \n",
        "  return all_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "tIwTNMdJYQOV",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning + creating API corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:36:50.009079Z",
          "start_time": "2020-05-15T12:36:50.002119Z"
        },
        "hidden": true,
        "id": "7SwUUwYNYQOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_repitations(sequence):\n",
        "    new_sequence = [x[0] for x in groupby(sequence)]\n",
        "    return new_sequence\n",
        "\n",
        "\n",
        "def data_cleaning(sequence_MIN_length,all_data):\n",
        "  # remove repitation in all data\n",
        "  all_data['API_sequence'] =all_data.apply(lambda x: remove_repitations(x['API_sequence']), axis=1)\n",
        "\n",
        "  # remove sequences shorter then sequence_MIN_length\n",
        "  print('Remove files with short sequence')\n",
        "  print('files before:',all_data.shape[0])\n",
        "  to_drop = []\n",
        "  for file in all_data['file_name']:\n",
        "      if len(all_data[all_data['file_name']==file].API_sequence.values[0]) < sequence_MIN_length:\n",
        "          to_drop.append(file)\n",
        "  all_data = all_data[~all_data['file_name'].isin(to_drop)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  return all_data\n",
        "\n",
        "\n",
        "def use_spesific_files(dataset_path,all_data):\n",
        "  balanced_csv = pd.read_csv(dataset_path)\n",
        "  print('files before:',all_data.shape[0])\n",
        "  all_data = all_data[all_data['file_name'].isin(balanced_csv['file_name'].values)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  return all_data\n",
        "\n",
        "# create API calls corpus\n",
        "def create_API_corpus(all_data):\n",
        "  API_corpus = []\n",
        "  for file in all_data['file_name']:\n",
        "      seq = all_data[all_data['file_name']==file].API_sequence.values[0]\n",
        "      API_corpus.extend(set(seq))\n",
        "  API_corpus = list(set(API_corpus))\n",
        "  print('API_corpus:',len(API_corpus))\n",
        "  return API_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "T19fW4K6YQOk",
        "colab_type": "text"
      },
      "source": [
        "# Representation Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "NJoeddnWYQOd",
        "colab_type": "text"
      },
      "source": [
        "## Functions: one-hot-encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:47.658061Z",
          "start_time": "2020-05-15T15:08:47.630084Z"
        },
        "hidden": true,
        "id": "XEztAvokYQOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_API_to_vector(Unique_API_calls,API):\n",
        "    if API != 0:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "        vec[Unique_API_calls.index(API)] = 1.0\n",
        "    else:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "    return list(vec)\n",
        "\n",
        "\n",
        "def create_sequence_n_nextWord_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    sequences = []\n",
        "    next_words = []\n",
        "    for seq in vectorized_data:\n",
        "        sequences.append(seq[:-1])\n",
        "        next_words.append(seq[len(seq)-1])\n",
        "    \n",
        "    return np.array(sequences),np.array(next_words)\n",
        "\n",
        "\n",
        "def create_sequence_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    return np.array(vectorized_data)\n",
        "\n",
        "\n",
        "def pruning_n_padding(seq,sequence_MAX_length):\n",
        "    final_seq = []\n",
        "    if len(seq) < sequence_MAX_length+1:\n",
        "        gap = (sequence_MAX_length) - len(seq)\n",
        "        zeros = [0] * gap\n",
        "        final_seq = list(zeros) + list(seq)\n",
        "    \n",
        "    elif len(seq) == sequence_MAX_length:\n",
        "        final_seq = list(seq)\n",
        "    \n",
        "    else:\n",
        "        final_seq = seq[:sequence_MAX_length]\n",
        "    return final_seq\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "BTyk8CV_YQOl",
        "colab_type": "text"
      },
      "source": [
        "## Predict next API call "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "pGte-d5ZYQOl",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:38:01.334154Z",
          "start_time": "2020-05-15T12:38:00.927149Z"
        },
        "hidden": true,
        "id": "2zgKHUCeYQOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_nextWord(data,sequence_MAX_length):\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length + next API as a label\n",
        "  LSTM_train_seq =  data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "  # create sequences and nextWords\n",
        "  train_vectorized_seq, train_vectorized_nextWord = create_sequence_n_nextWord_one_hot(LSTM_train_seq)\n",
        "\n",
        "  print('train_vectorized_seq:',train_vectorized_seq.shape, ' train_vectorized_nextWord:',train_vectorized_nextWord.shape)\n",
        "\n",
        "  return train_vectorized_seq, train_vectorized_nextWord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "jpOTUQFlYQOq",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 1:###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "wz0mDQ9-YQOr",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:39:04.994653Z",
          "start_time": "2020-05-15T12:39:04.985659Z"
        },
        "hidden": true,
        "id": "o9hBvvi5YQOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM Params\n",
        "output_dim = len(API_corpus)\n",
        "input_seq_size = len(API_corpus)\n",
        "input_time_dim = None\n",
        "nb_units =500\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:39:15.989070Z",
          "start_time": "2020-05-15T12:39:05.000660Z"
        },
        "hidden": true,
        "id": "6_SiUrHUYQOt",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ae86d61-0c4a-4113-c4dc-2c36055c24e3"
      },
      "source": [
        "# Seed value\n",
        "seed_value= 0\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# build the model\n",
        "model_1 = Sequential()\n",
        "model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                 activation='tanh',dropout=0.1 ,return_sequences=True))\n",
        "model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                 activation='tanh',dropout=0.1,return_sequences=False))\n",
        "model_1.add(Dense(output_dim,activation='softmax'))\n",
        "model_1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, None, 500)         1608000   \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 500)               2002000   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 303)               151803    \n",
            "=================================================================\n",
            "Total params: 3,761,803\n",
            "Trainable params: 3,761,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.751830Z",
          "start_time": "2020-05-15T12:39:15.991098Z"
        },
        "collapsed": true,
        "hidden": true,
        "id": "qs4t-mEoYQOv",
        "colab_type": "code",
        "colab": {},
        "outputId": "4ee2ddde-9b80-495a-d4f8-20f122461732"
      },
      "source": [
        "model_1.fit(train_vectorized_seq,train_vectorized_nextWord, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4932/4932 [==============================] - 1673s 339ms/step - loss: 3.7288 - acc: 0.1575\n",
            "Epoch 2/10\n",
            "4932/4932 [==============================] - 1674s 339ms/step - loss: 3.7574 - acc: 0.1500\n",
            "Epoch 3/10\n",
            "4932/4932 [==============================] - 1651s 335ms/step - loss: 3.6044 - acc: 0.1636\n",
            "Epoch 4/10\n",
            "4932/4932 [==============================] - 1670s 339ms/step - loss: 3.5738 - acc: 0.1636\n",
            "Epoch 5/10\n",
            "4932/4932 [==============================] - 1675s 340ms/step - loss: 3.5440 - acc: 0.1636\n",
            "Epoch 6/10\n",
            " 928/4932 [====>.........................] - ETA: 22:33 - loss: 3.4824 - acc: 0.1670"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-255-832c2563dc71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vectorized_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_vectorized_nextWord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\finderi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "rWtO0iVHYQOx",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.756860Z",
          "start_time": "2020-05-15T12:36:46.294Z"
        },
        "hidden": true,
        "id": "p69VSdGBYQOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model_1.predict(test_vectorized_seq)\n",
        "decoded_preds = []\n",
        "for idx in range(predictions.shape[0]):\n",
        "    decoded = API_corpus[np.argmax(predictions[idx])]\n",
        "    decoded_preds.append(decoded)\n",
        "    \n",
        "decoded_true = []\n",
        "for idx in range(test_vectorized_nextWord.shape[0]):\n",
        "    decoded = API_corpus[np.argmax(test_vectorized_nextWord[idx])]\n",
        "    decoded_true.append(decoded)\n",
        "\n",
        "set(decoded_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.759836Z",
          "start_time": "2020-05-15T12:36:46.724Z"
        },
        "hidden": true,
        "id": "birs8taeYQO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "for idx in range(len(decoded_preds)):\n",
        "    if decoded_preds[idx] == decoded_true[idx]:\n",
        "        correct += 1\n",
        "        \n",
        "print('test accuracy:', round(correct/len(decoded_preds),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "p5607GpfYQO5",
        "colab_type": "text"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.762865Z",
          "start_time": "2020-05-15T12:36:48.260Z"
        },
        "hidden": true,
        "id": "Rrj8XB4sYQO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model\n",
        "model_1.save('./LSTM_models/arch_1_LSTM_nextWord.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "RvgQTumJYQO8",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 2: (Optional)###\n",
        "- Input: integers\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Mk6Gtc2sYQO8",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 3: (Optional)###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 1 LSTM layers (return_sequence=True)+ Dense using softmax\n",
        "- Feed the model with the next API for each input cell (offset of the APIs)\n",
        "- Next, remove the last Dense layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "FF650hUBYQO-",
        "colab_type": "text"
      },
      "source": [
        "## Predict final label (0/1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "5QaoG-gMYQO_",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:40.423935Z",
          "start_time": "2020-05-15T15:08:40.370936Z"
        },
        "hidden": true,
        "id": "PAGtmh8OYQO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_finalLabel(x_data, y_data,sequence_MAX_length):\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length\n",
        "  LSTM_train_seq =  x_data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "\n",
        "  # convert API sequence to one-hot-encoding vectors\n",
        "  train_vectorized_seq = create_sequence_one_hot(LSTM_train_seq)\n",
        "\n",
        "  # convert class to 0 and 1\n",
        "  rep_train_labels = np.array(y_data.apply(lambda x: 1 if x == 'malicious' else 0).values,dtype=np.float32)\n",
        "\n",
        "  print('train_vectorized_seq:',train_vectorized_seq.shape, ' train_labels:',rep_train_labels.shape)\n",
        "\n",
        "  return train_vectorized_seq, rep_train_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "oF6TPDGUYQPE",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 1:###\n",
        "- Train model with 2 LSTM layers + Dense using sigmoid\n",
        "- Predict the class using the second layer last-cell \n",
        "- Next, remove the second LSTM layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "dxTRoY6hYQPE",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:33:56.855816Z",
          "start_time": "2020-05-15T15:33:55.003172Z"
        },
        "hidden": true,
        "id": "fgUpIJcWYQPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_finalLabel_arch_1(input_seq_size,input_time_dim,nb_units,dropout):\n",
        "  # Seed value\n",
        "  seed_value= 0\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  tf.set_random_seed(seed_value)\n",
        "\n",
        "  # build the model\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout ,return_sequences=True))\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout,return_sequences=False))\n",
        "  model_2.add(Dense(1, activation='sigmoid'))\n",
        "  model_2.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  print(model_2.summary())\n",
        "  return model_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9IiF9WS7YQPL",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:00.378396Z",
          "start_time": "2020-05-15T16:28:16.113640Z"
        },
        "hidden": true,
        "id": "cJoSHea_YQPL",
        "colab_type": "code",
        "colab": {},
        "outputId": "2bb2e0f1-f6de-414d-ba74-ba2dc593a4f6"
      },
      "source": [
        "def evaluate_LSTM(model,test_vectorized_seq,rep_test_labels):\n",
        "  predictions = model.predict(test_vectorized_seq)\n",
        "\n",
        "  final_preds = []\n",
        "\n",
        "  for pred in predictions:\n",
        "      if pred > 0.5:\n",
        "          final_preds.append(1.0)\n",
        "      else:\n",
        "          final_preds.append(0.0)\n",
        "          \n",
        "  correct = 0\n",
        "  for idx, pred in enumerate(final_preds):\n",
        "      if final_preds[idx] == rep_test_labels[idx]:\n",
        "          correct+=1\n",
        "  print('accuracy:',round(correct/len(final_preds),4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OKq1JUEYQPP",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction - from LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ay7iywNYQPP",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:19.285809Z",
          "start_time": "2020-05-15T16:29:19.212801Z"
        },
        "id": "U4fGjb17YQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prepare_data_classification(data, sequence_MAX_length):\n",
        "  # pruning the sequences to match sequence_MAX_length \n",
        "  rep_train_seq =  data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "  return rep_train_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BL7ZJpYQPR",
        "colab_type": "text"
      },
      "source": [
        "## Extract features using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:21.909349Z",
          "start_time": "2020-05-15T16:29:21.891314Z"
        },
        "id": "Lxn7loXAYQPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_vector_maxPool_n_lastCell(trained_model, sequence_data):\n",
        "  # Seed value\n",
        "  seed_value= 0\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  tf.set_random_seed(seed_value)\n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model.add(layer)\n",
        "\n",
        "  preds = new_model.predict(sequence_data)\n",
        "\n",
        "  # save all the last lstm cell outputs\n",
        "  last_cell_outputs = []\n",
        "  for file in preds:\n",
        "      last_cell_outputs.append(file[-1]) \n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model_max_pooling = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model_max_pooling.add(layer)\n",
        "\n",
        "  # add softmax + max pooling layer\n",
        "  new_model_max_pooling.add(GlobalMaxPooling1D())\n",
        "  max_pooling_vectors = new_model_max_pooling.predict(sequence_data)\n",
        "\n",
        "  \n",
        "  # Creating the representation vectors:\n",
        "  # concatenating the max-pooling with the last output\n",
        "  final_representation = []\n",
        "  for idx,max_pool in enumerate(max_pooling_vectors):\n",
        "      new_vector = list(max_pool) + list(last_cell_outputs[idx])\n",
        "      final_representation.append(new_vector)\n",
        "  final_representation = np.array(final_representation,dtype=np.float32)\n",
        "  \n",
        "  return final_representation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:48:30.977421Z",
          "start_time": "2020-05-15T16:30:43.348085Z"
        },
        "id": "e_cy17fKYQPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_final_feature_vector(trained_model,rep_train_seq,one_hot_encoding):\n",
        "  if one_hot_encoding:\n",
        "    print('creating one-hot-encoding')\n",
        "    # create sequences (one-hote encoding format) *we dont use the nextWord here\n",
        "    train_vectorized_seq = create_sequence_one_hot(rep_train_seq)\n",
        "    print('Creating feature vectors')\n",
        "    train_feature_vector = feature_vector_maxPool_n_lastCell(trained_model, train_vectorized_seq)\n",
        "\n",
        "  return train_feature_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzUU3oYDYQPV",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdCT0a9bYQPV",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:51:39.756457Z",
          "start_time": "2020-05-15T16:51:37.600805Z"
        },
        "id": "l2eEtZPwYQPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocessing(x_data,y_data):\n",
        "  # convert class to 0 and 1\n",
        "  labels = y_data.apply(lambda x: 1 if x == 'malicious' else 0).values\n",
        "  # Normalizing the data\n",
        "  data = StandardScaler().fit_transform(x_data)\n",
        "\n",
        "  return data,labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7SMtghsYQPX",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "8YJxffN2YQPY",
        "colab_type": "text"
      },
      "source": [
        "### Functions: classifier evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T11:43:02.671328Z",
          "start_time": "2020-05-15T11:43:02.645329Z"
        },
        "hidden": true,
        "id": "TayLH2KMYQPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_metrics(conf_matrix, Y_proba, Y_test):\n",
        "    AUC = roc_auc_score(Y_test, Y_proba)\n",
        "\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "\n",
        "    TPR = TP / (TP + FN)\n",
        "    FPR = FP / (FP + TN)\n",
        "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
        "    Precision = TP / (TP + FP)\n",
        "    F1_score = 2 * ((Precision * TPR) / (Precision + TPR))\n",
        "\n",
        "    metrics_dict = {\n",
        "        'TPR': round(TPR, 2),\n",
        "        'FPR': round(FPR, 2),\n",
        "        'ACC': round(ACC, 2),\n",
        "        'Precision': round(Precision, 2),\n",
        "        'F1_score': round(F1_score, 2),\n",
        "        'AUC': round(AUC, 4),\n",
        "    }\n",
        "\n",
        "    return metrics_dict\n",
        "\n",
        "\n",
        "def convert_class_to_binary(label):\n",
        "    if label == 'malicious':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "def get_predictions(Y_proba, threshold):\n",
        "    Y_pred_final = []\n",
        "    for p in Y_proba:\n",
        "        if p >= threshold:\n",
        "            Y_pred_final.append(1)\n",
        "        else:\n",
        "            Y_pred_final.append(0)\n",
        "\n",
        "    return Y_pred_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tklOI_8eYQPZ",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG-6AlkXYQPb",
        "colab_type": "text"
      },
      "source": [
        "**CrossValidation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC2gFGAdYQPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOfXEsTNzO7v",
        "colab_type": "text"
      },
      "source": [
        "# Main\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFangIGCDjl3",
        "colab_type": "text"
      },
      "source": [
        "## Load & clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiiHQYkyDb2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "74ebcfb5-7270-4ffc-c195-a314f23d70f2"
      },
      "source": [
        "benign_path = '../Cuckoo_Parser/Parsed_Data/win10/benign_parquet_updated'\n",
        "malware_path = '../Cuckoo_Parser/Parsed_Data/win10/malware_parquet_updated'\n",
        "\n",
        "# all_data = load_raw_parquets(benign_path, malware_path)\n",
        "# all_data.to_pickle('data_for_LSTM.pkl')\n",
        "all_data = pd.read_pickle('/content/drive/My Drive/Thesis/RNN_LSTM/data_for_LSTM.pkl')\n",
        "\n",
        "# Clean data (remove short sequence & remove duplications)\n",
        "sequence_MIN_length = 15 # (Pascano, 2015)\n",
        "all_data = data_cleaning(sequence_MIN_length,all_data)\n",
        "\n",
        "# use file from other experiments\n",
        "dataset_name = '1_Balanced_Frequencies_first1000sec_minAPI_15_minRunTime_0_withYara_No.csv'\n",
        "folder_path = '/content/drive/My Drive/Thesis/RNN_LSTM/balaned_datasets'\n",
        "full_path = '{}/{}'.format(folder_path,dataset_name)\n",
        "all_data = use_spesific_files(full_path,all_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove files with short sequence\n",
            "files before: 7156\n",
            "files after: 6166\n",
            "files before: 6166\n",
            "files after: 4531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_2tygDfDebw",
        "colab_type": "text"
      },
      "source": [
        "## strat cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx-gvpMq2GQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data_sequences = all_data['API_sequence']\n",
        "data_labels = all_data['class']\n",
        "\n",
        "\n",
        "folds_TPR, folds_FPR, folds_ACC, folds_F1_score, folds_Precision, folds_AUC = [], [], [], [], [], []\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
        "fold = 0\n",
        "for train, test in kfold.split(data_sequences, data_labels):\n",
        "    fold += 1\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = data_sequences[train], data_labels[train], data_sequences[test], data_labels[test]\n",
        "\n",
        "    # prepare data for representation model (Optional)\n",
        "    sequence_MAX_length = 50 # (Athiwaratkun, 2017)\n",
        "    sequence_MAX_length = 100 # (Pascanu, 2015)\n",
        "\n",
        "    x_train,Y_train = prepare_data_finalLabel(X_train,Y_train,sequence_MAX_length)\n",
        "\n",
        "    # Init LSTM model\n",
        "    output_dim = len(API_corpus)\n",
        "    input_seq_size = len(API_corpus)\n",
        "    input_time_dim = None\n",
        "    nb_units = 100\n",
        "    dropout = 0.1\n",
        "    epochs = 5\n",
        "\n",
        "    LSTM_model = LSTM_finalLabel_arch_1(input_seq_size,input_time_dim,nb_units,dropout)\n",
        "\n",
        "    # train model on training data\n",
        "    LSTM_model.fit(train_vectorized_seq,rep_train_labels, epochs=epochs)\n",
        "\n",
        "    \n",
        "    # mid-process evaluation of the rpresentation learning model\n",
        "    evaluate_LSTM(LSTM_model,test_vectorized_seq,rep_test_labels)\n",
        "\n",
        "    # save the model\n",
        "    # model_2.save('./LSTM_models/arch_1_LSTM_finalLabel.hdf5')\n",
        "\n",
        "    # create feature vector - feature extraction\n",
        "    sequence_MAX_length = 200 #(Agrawal 2018 , Athiwaratkun 2017)\n",
        "    one_hot_encoding = True\n",
        "\n",
        "    # TODO: orgenaize all the preprocessing functions\n",
        "    rep_train_seq = prepare_data_classification(train_data, sequence_MAX_length)\n",
        "\n",
        "    final_train_vector = create_final_feature_vector(LSTM_model,rep_train_seq,one_hot_encoding)\n",
        "\n",
        "    x_data, y_data = data_preprocessing(x_data,y_data)\n",
        "\n",
        "    # train classifier\n",
        "    LR = LogisticRegression(max_iter=1000)\n",
        "    LR.fit(train_feature_vector_norm, rep_train_labels)\n",
        "\n",
        "    # predict\n",
        "    # Get probability for each class\n",
        "    Y_proba = LR.predict_proba(X_test)[:, 1]\n",
        "    # convert probabilities into predictions based on the threshold\n",
        "    Y_pred = get_predictions(Y_proba, threshold=0.5)\n",
        "\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "    # calc all the relevant metrics\n",
        "    metrics = calc_metrics(conf_matrix, Y_proba, Y_test)\n",
        "    metrics_print = '\\tTPR:{}\\tFPR:{}\\tACC:{}\\tPrecision:{}\\tF1_score:{}\\tAUC:{}'.format(metrics['TPR'],\n",
        "                                                                                         metrics['FPR'],\n",
        "                                                                                         metrics['ACC'],\n",
        "                                                                                         metrics['Precision'],\n",
        "                                                                                         metrics['F1_score'],\n",
        "                                                                                         metrics['AUC'])\n",
        "\n",
        "    print('[Fold {}/{}] -\\t{}:\\t{} '.format(fold, 5, 'LR', metrics_print))\n",
        "\n",
        "    folds_TPR.append(metrics['TPR'])\n",
        "    folds_FPR.append(metrics['FPR'])\n",
        "    folds_ACC.append(metrics['ACC'])\n",
        "    folds_Precision.append(metrics['Precision'])\n",
        "    folds_F1_score.append(metrics['F1_score'])\n",
        "    folds_AUC.append(metrics['AUC'])\n",
        "  \n",
        "# print CV results\n",
        "print('\\nFinal Results: {} samples'.format(rep_test_labels.shape[0]))\n",
        "print('TPR:', round(np.mean(folds_TPR),4))\n",
        "print('FPR:', round(np.mean(folds_FPR),4))\n",
        "print('ACC:', round(np.mean(folds_ACC),4))\n",
        "print('Precision:', round(np.mean(folds_Precision),4))\n",
        "print('F1_score:', round(np.mean(folds_F1_score),4))\n",
        "print('AUC:', round(np.mean(folds_AUC),4))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}