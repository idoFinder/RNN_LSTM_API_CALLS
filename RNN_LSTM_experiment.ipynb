{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "RNN_LSTM_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RvgQTumJYQO8"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idoFinder/RNN_LSTM_API_CALLS/blob/master/RNN_LSTM_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:17:35.118725Z",
          "start_time": "2020-05-15T12:17:35.105725Z"
        },
        "id": "ATAoBNAOYQOE",
        "colab_type": "code",
        "outputId": "d98c7930-cd26-430b-c9c7-644c367aca70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential, load_model ,Model\n",
        "from keras.layers import Dense, LSTM,Embedding,GlobalMaxPooling1D,Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score, confusion_matrix, accuracy_score, recall_score,plot_confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing, metrics\n",
        "from itertools import groupby\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98EJvMiXYb8P",
        "colab_type": "code",
        "outputId": "645983c3-4dd3-4c99-a2f0-d05d1f96eb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hM383LbYf7h",
        "colab_type": "code",
        "outputId": "1e4c444e-ddff-4377-eb53-676c39504ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "1_DDCKXKYQOK",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "9q75_tgAYQOK",
        "colab_type": "text"
      },
      "source": [
        "## Read raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T20:14:53.413431Z",
          "start_time": "2020-05-14T19:22:12.518448Z"
        },
        "hidden": true,
        "id": "jeWKDRpMYQOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_raw_parquets(benign_path, malware_path):\n",
        "  # load benign parquets\n",
        "  all_data = pd.DataFrame(columns=['file_name','API_sequence','class'])\n",
        "  for idx, batch_path in enumerate(os.listdir(benign_path)):\n",
        "      path = '{}/{}'.format(folder_path,batch_path)\n",
        "      batch = pd.read_parquet(path)\n",
        "      files = batch['file_name'].unique()\n",
        "      new_records = []\n",
        "      for file in files:\n",
        "          sub_df = batch[batch['file_name']==file].sort_values(['normalized_time'])\n",
        "          new_record = {'file_name':file,'API_sequence':sub_df['API'].values,'class':'benign'}\n",
        "          new_records.append(new_record)\n",
        "      all_data = all_data.append(new_records, ignore_index=True)\n",
        "      print('batch',idx+1, ' loaded')\n",
        "      \n",
        "  # load malicious parquets\n",
        "  for idx, batch_path in enumerate(os.listdir(malware_path)):\n",
        "      path = '{}/{}'.format(folder_path,batch_path)\n",
        "      batch = pd.read_parquet(path)\n",
        "      files = batch['file_name'].unique()\n",
        "      new_records = []\n",
        "      for file in files:\n",
        "          sub_df = batch[batch['file_name']==file].sort_values(['normalized_time'])\n",
        "          new_record = {'file_name':file,'API_sequence':sub_df['API'].values,'class':'malicious'}\n",
        "          new_records.append(new_record)\n",
        "      all_data = all_data.append(new_records, ignore_index=True)\n",
        "      print('batch',idx+1, ' loaded')\n",
        "    \n",
        "  return all_data\n",
        "\n",
        "\n",
        "\n",
        "def get_classes_distribution_df(df):\n",
        "    num_of_benign = df[df['class'] == 'benign'].shape[0]\n",
        "    num_of_malware = df[df['class'] == 'malicious'].shape[0]\n",
        "    total = num_of_benign + num_of_malware\n",
        "    benign_perc = round((num_of_benign / total) * 100, 2)\n",
        "    malware_perc = round((num_of_malware / total) * 100, 2)\n",
        "    res_str = 'Benign:{} ({}%) | Malicious:{} ({}%)'.format(num_of_benign, benign_perc, num_of_malware, malware_perc)\n",
        "    return res_str\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "tIwTNMdJYQOV",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning + creating API corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:36:50.009079Z",
          "start_time": "2020-05-15T12:36:50.002119Z"
        },
        "hidden": true,
        "id": "7SwUUwYNYQOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_repitations(sequence):\n",
        "    new_sequence = [x[0] for x in groupby(sequence)]\n",
        "    return new_sequence\n",
        "\n",
        "\n",
        "def data_cleaning(sequence_MIN_length,all_data):\n",
        "  # remove repitation in all data\n",
        "  all_data['API_sequence'] =all_data.apply(lambda x: remove_repitations(x['API_sequence']), axis=1)\n",
        "\n",
        "  # remove sequences shorter then sequence_MIN_length\n",
        "  print('Remove files with short sequence')\n",
        "  print('files before:',all_data.shape[0])\n",
        "  to_drop = []\n",
        "  for file in all_data['file_name']:\n",
        "      if len(all_data[all_data['file_name']==file].API_sequence.values[0]) < sequence_MIN_length:\n",
        "          to_drop.append(file)\n",
        "  all_data = all_data[~all_data['file_name'].isin(to_drop)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  all_data = all_data.reset_index(drop=True)\n",
        "  return all_data\n",
        "\n",
        "\n",
        "def use_spesific_files(dataset_path,all_data):\n",
        "  balanced_csv = pd.read_csv(dataset_path)\n",
        "  print('files before:',all_data.shape[0])\n",
        "  all_data = all_data[all_data['file_name'].isin(balanced_csv['file_name'].values)]\n",
        "  print('files after:',all_data.shape[0])\n",
        "  all_data = all_data.reset_index(drop=True)\n",
        "  return all_data\n",
        "\n",
        "# create API calls corpus\n",
        "def create_API_corpus(all_data):\n",
        "  API_corpus = []\n",
        "  for file in all_data['file_name']:\n",
        "      seq = all_data[all_data['file_name']==file].API_sequence.values[0]\n",
        "      API_corpus.extend(set(seq))\n",
        "  API_corpus = list(set(API_corpus))\n",
        "  print('API_corpus:',len(API_corpus))\n",
        "  return API_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "T19fW4K6YQOk",
        "colab_type": "text"
      },
      "source": [
        "# Representation Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "NJoeddnWYQOd",
        "colab_type": "text"
      },
      "source": [
        "## Functions: one-hot-encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:47.658061Z",
          "start_time": "2020-05-15T15:08:47.630084Z"
        },
        "hidden": true,
        "id": "XEztAvokYQOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_API_to_vector(Unique_API_calls,API):\n",
        "    if API != 0:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "        vec[Unique_API_calls.index(API)] = 1.0\n",
        "    else:\n",
        "        vec = np.zeros((len(Unique_API_calls),), dtype=np.float32)\n",
        "    return list(vec)\n",
        "\n",
        "\n",
        "def create_sequence_n_nextWord_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    sequences = []\n",
        "    next_words = []\n",
        "    for seq in vectorized_data:\n",
        "        sequences.append(seq[:-1])\n",
        "        next_words.append(seq[len(seq)-1])\n",
        "    \n",
        "    return np.array(sequences),np.array(next_words)\n",
        "\n",
        "\n",
        "def create_sequence_one_hot(data):\n",
        "    vectorized_data = []\n",
        "    for idx in range(len(data)):\n",
        "        seq = data.iloc[idx]\n",
        "        vector = []\n",
        "        for api in seq:\n",
        "            vector.append(convert_API_to_vector(API_corpus,api))\n",
        "        vectorized_data.append(vector)\n",
        "    \n",
        "    return np.array(vectorized_data)\n",
        "\n",
        "\n",
        "def pruning_n_padding(seq,sequence_MAX_length):\n",
        "    final_seq = []\n",
        "    if len(seq) < sequence_MAX_length+1:\n",
        "        gap = (sequence_MAX_length) - len(seq)\n",
        "        zeros = [0] * gap\n",
        "        final_seq = list(zeros) + list(seq)\n",
        "    \n",
        "    elif len(seq) == sequence_MAX_length:\n",
        "        final_seq = list(seq)\n",
        "    \n",
        "    else:\n",
        "        final_seq = seq[:sequence_MAX_length]\n",
        "    return final_seq\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "BTyk8CV_YQOl",
        "colab_type": "text"
      },
      "source": [
        "## Predict next API call "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "pGte-d5ZYQOl",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:38:01.334154Z",
          "start_time": "2020-05-15T12:38:00.927149Z"
        },
        "hidden": true,
        "id": "2zgKHUCeYQOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_nextWord(data,sequence_MAX_length):\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length + next API as a label\n",
        "  LSTM_train_seq =  data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "  # create sequences and nextWords\n",
        "  train_vectorized_seq, train_vectorized_nextWord = create_sequence_n_nextWord_one_hot(LSTM_train_seq)\n",
        "\n",
        "  # print('train_vectorized_seq:',train_vectorized_seq.shape, ' train_vectorized_nextWord:',train_vectorized_nextWord.shape)\n",
        "\n",
        "  return train_vectorized_seq, train_vectorized_nextWord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "jpOTUQFlYQOq",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 1:###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "wz0mDQ9-YQOr",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T12:39:15.989070Z",
          "start_time": "2020-05-15T12:39:05.000660Z"
        },
        "hidden": true,
        "id": "6_SiUrHUYQOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_nextWord_arch_1(output_dim,input_seq_size,input_time_dim,nb_units,dropout):\n",
        "  seed_value= 10\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  # build the model\n",
        "  model_1 = Sequential()\n",
        "  model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout ,return_sequences=True))\n",
        "  model_1.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout,return_sequences=False))\n",
        "  model_1.add(Dense(output_dim,activation='softmax'))\n",
        "  model_1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  # print(model_1.summary())\n",
        "  return model_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "rWtO0iVHYQOx",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:03:46.756860Z",
          "start_time": "2020-05-15T12:36:46.294Z"
        },
        "hidden": true,
        "id": "p69VSdGBYQOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_LSTM_nextWord(model,x_test,y_test):\n",
        "  predictions = model.predict(x_test)\n",
        "  decoded_preds = []\n",
        "  for idx in range(predictions.shape[0]):\n",
        "      decoded = API_corpus[np.argmax(predictions[idx])]\n",
        "      decoded_preds.append(decoded)\n",
        "      \n",
        "  decoded_true = []\n",
        "  for idx in range(y_test.shape[0]):\n",
        "      decoded = API_corpus[np.argmax(x_test[idx])]\n",
        "      decoded_true.append(decoded)\n",
        "\n",
        "  print('predicted corpus:', str(set(decoded_preds)))\n",
        "\n",
        "  correct = 0\n",
        "  for idx in range(len(decoded_preds)):\n",
        "      if decoded_preds[idx] == decoded_true[idx]:\n",
        "          correct += 1\n",
        "          \n",
        "  print('LSTM representation accuracy:', round(correct/len(decoded_preds),3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "RvgQTumJYQO8",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 2: (Optional)###\n",
        "- Input: integers\n",
        "- Train model with 2 LSTM layers + Dense using softmax\n",
        "- Predict the next API call using the second layer last-cell (argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Mk6Gtc2sYQO8",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 3: (Optional)###\n",
        "- Input: One-hot-encoding\n",
        "- Train model with 1 LSTM layers (return_sequence=True)+ Dense using softmax\n",
        "- Feed the model with the next API for each input cell (offset of the APIs)\n",
        "- Next, remove the last Dense layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "FF650hUBYQO-",
        "colab_type": "text"
      },
      "source": [
        "## Predict final label (0/1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "5QaoG-gMYQO_",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:08:40.423935Z",
          "start_time": "2020-05-15T15:08:40.370936Z"
        },
        "hidden": true,
        "id": "PAGtmh8OYQO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_finalLabel(x_data, y_data,sequence_MAX_length):\n",
        "  # print('Preparing data - final Label LSTM')\n",
        "\n",
        "  # pruning the sequences to match sequence_MAX_length\n",
        "  LSTM_train_seq =  x_data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "\n",
        "  # convert API sequence to one-hot-encoding vectors\n",
        "  train_vectorized_seq = create_sequence_one_hot(LSTM_train_seq)\n",
        "\n",
        "  # convert class to 0 and 1\n",
        "  rep_train_labels = np.array(y_data.apply(lambda x: 1 if x == 'malicious' else 0).values,dtype=np.float32)\n",
        "\n",
        "  # print('x_data shape:',train_vectorized_seq.shape, ' y_data shape:',rep_train_labels.shape)\n",
        "\n",
        "  return np.array(train_vectorized_seq), np.array(rep_train_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "oF6TPDGUYQPE",
        "colab_type": "text"
      },
      "source": [
        "### Architecture 1:###\n",
        "- Train model with 2 LSTM layers + Dense using sigmoid\n",
        "- Predict the class using the second layer last-cell \n",
        "- Next, remove the second LSTM layer and perform GlobalMaxPooling for the representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "dxTRoY6hYQPE",
        "colab_type": "text"
      },
      "source": [
        "**First stage - train LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T15:33:56.855816Z",
          "start_time": "2020-05-15T15:33:55.003172Z"
        },
        "hidden": true,
        "id": "fgUpIJcWYQPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_finalLabel_arch_1(input_seq_size,input_time_dim,nb_units,dropout):\n",
        "  # Seed value\n",
        "  seed_value= 10\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  print('Bulding LSTM model - final Label (arch 1)')\n",
        "\n",
        "  # build the model\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout ,return_sequences=True))\n",
        "  model_2.add(LSTM(units=nb_units, input_shape=(input_time_dim,input_seq_size),\n",
        "                  activation='tanh',dropout=dropout,return_sequences=False))\n",
        "  model_2.add(Dense(1, activation='sigmoid'))\n",
        "  model_2.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  # print(model_2.summary())\n",
        "  return model_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9IiF9WS7YQPL",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate the LSTM training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:00.378396Z",
          "start_time": "2020-05-15T16:28:16.113640Z"
        },
        "hidden": true,
        "id": "cJoSHea_YQPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_LSTM_finalLabel(model,x_test,y_test):\n",
        "\n",
        "  predictions = model.predict(x_test)\n",
        "  final_preds = []\n",
        "  for pred in predictions:\n",
        "      if pred > 0.5:\n",
        "          final_preds.append(1.0)\n",
        "      else:\n",
        "          final_preds.append(0.0)\n",
        "          \n",
        "  correct = 0\n",
        "  for idx, pred in enumerate(final_preds):\n",
        "      if final_preds[idx] == y_test[idx]:\n",
        "          correct+=1\n",
        "  print('LSTM representation accuracy:',round(correct/len(final_preds),4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OKq1JUEYQPP",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction - from LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BL7ZJpYQPR",
        "colab_type": "text"
      },
      "source": [
        "## Extract features using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:29:21.909349Z",
          "start_time": "2020-05-15T16:29:21.891314Z"
        },
        "id": "Lxn7loXAYQPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_vector_maxPool_n_lastCell(trained_model, sequence_data):\n",
        "  # Seed value\n",
        "  seed_value= 0\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  # tf.set_random_seed(seed_value)\n",
        "  tf.random.set_seed(seed_value)\n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model.add(layer)\n",
        "\n",
        "  preds = new_model.predict(sequence_data)\n",
        "\n",
        "  # save all the last lstm cell outputs\n",
        "  last_cell_outputs = []\n",
        "  for file in preds:\n",
        "      last_cell_outputs.append(file[-1]) \n",
        "\n",
        "  # remove the last two layers: Dense + last LSTM \n",
        "  new_model_max_pooling = Sequential()\n",
        "  for layer in trained_model.layers[:-2]:\n",
        "      new_model_max_pooling.add(layer)\n",
        "\n",
        "  # add softmax + max pooling layer\n",
        "  new_model_max_pooling.add(GlobalMaxPooling1D())\n",
        "  max_pooling_vectors = new_model_max_pooling.predict(sequence_data)\n",
        "\n",
        "  \n",
        "  # Creating the representation vectors:\n",
        "  # concatenating the max-pooling with the last output\n",
        "  final_representation = []\n",
        "  for idx,max_pool in enumerate(max_pooling_vectors):\n",
        "      new_vector = list(max_pool) + list(last_cell_outputs[idx])\n",
        "      final_representation.append(new_vector)\n",
        "  final_representation = np.array(final_representation,dtype=np.float32)\n",
        "  # print('final shape:', str(final_representation.shape) )\n",
        "  \n",
        "  return final_representation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T16:48:30.977421Z",
          "start_time": "2020-05-15T16:30:43.348085Z"
        },
        "id": "e_cy17fKYQPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_feature_vector(trained_model,x_data,y_data,one_hot_encoding,sequence_MAX_length):\n",
        "  # pruning the sequences to match sequence_MAX_length \n",
        "  rep_train_seq =  x_data.apply(lambda x: pruning_n_padding(x,sequence_MAX_length))\n",
        "\n",
        "  # convert class to 0 and 1\n",
        "  labels = y_data.apply(lambda x: 1 if x == 'malicious' else 0).values\n",
        "\n",
        "  if one_hot_encoding:\n",
        "    # print('creating one-hot-encoding')\n",
        "    # create sequences (one-hote encoding format) *we dont use the nextWord here\n",
        "    train_vectorized_seq = create_sequence_one_hot(rep_train_seq)\n",
        "    # print('Creating feature vectors')\n",
        "    train_feature_vector = feature_vector_maxPool_n_lastCell(trained_model, train_vectorized_seq)\n",
        "\n",
        "  return np.array(train_feature_vector), np.array(labels, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzUU3oYDYQPV",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-15T11:43:02.671328Z",
          "start_time": "2020-05-15T11:43:02.645329Z"
        },
        "hidden": true,
        "id": "TayLH2KMYQPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_metrics(conf_matrix, Y_proba, Y_test):\n",
        "    AUC = roc_auc_score(Y_test, Y_proba)\n",
        "\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "\n",
        "    TPR = TP / (TP + FN)\n",
        "    FPR = FP / (FP + TN)\n",
        "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
        "    Precision = TP / (TP + FP)\n",
        "    F1_score = 2 * ((Precision * TPR) / (Precision + TPR))\n",
        "\n",
        "    metrics_dict = {\n",
        "        'TPR': round(TPR, 2),\n",
        "        'FPR': round(FPR, 2),\n",
        "        'ACC': round(ACC, 2),\n",
        "        'Precision': round(Precision, 2),\n",
        "        'F1_score': round(F1_score, 2),\n",
        "        'AUC': round(AUC, 4),\n",
        "    }\n",
        "\n",
        "    return metrics_dict\n",
        "\n",
        "\n",
        "def convert_class_to_binary(label):\n",
        "    if label == 'malicious':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "def get_predictions(Y_proba, threshold):\n",
        "    Y_pred_final = []\n",
        "    for p in Y_proba:\n",
        "        if p >= threshold:\n",
        "            Y_pred_final.append(1.0)\n",
        "        else:\n",
        "            Y_pred_final.append(0.0)\n",
        "\n",
        "    return np.array(Y_pred_final)\n",
        "\n",
        "def LR_fit(x_train, y_train, max_iter):\n",
        "\n",
        "  # normalizing the data\n",
        "  x_train_final = StandardScaler().fit_transform(x_train)\n",
        "  # init model + fit\n",
        "  LR = LogisticRegression(max_iter=max_iter)\n",
        "  LR.fit(x_train_final, y_train)\n",
        "\n",
        "  return LR\n",
        "\n",
        "\n",
        "def LR_predict(model,x_test):\n",
        "  # Get probability for each class\n",
        "  x_test_final = StandardScaler().fit_transform(x_test)\n",
        "  y_proba = model.predict_proba(x_test_final)[:, 1]\n",
        "  # convert probabilities into predictions based on the threshold\n",
        "  y_pred = get_predictions(y_proba, threshold=0.5)\n",
        "\n",
        "  return y_pred,y_proba\n",
        "\n",
        "def LSTM_predict(model, x_test):\n",
        "  # Get probability for each class\n",
        "  y_proba = model.predict(x_test)\n",
        "  # convert probabilities into predictions based on the threshold\n",
        "  y_pred = get_predictions(y_proba, threshold=0.5)\n",
        "\n",
        "  return y_pred,y_proba\n",
        "\n",
        "\n",
        "def print_final_results(y_test,folds_TPR,folds_FPR,folds_ACC,folds_Precision,folds_F1_score,folds_AUC):\n",
        "  print('\\nFinal Results: {} samples'.format(y_test.shape[0]))\n",
        "  print('TPR:', round(np.mean(folds_TPR),4))\n",
        "  print('FPR:', round(np.mean(folds_FPR),4))\n",
        "  print('ACC:', round(np.mean(folds_ACC),4))\n",
        "  print('Precision:', round(np.mean(folds_Precision),4))\n",
        "  print('F1_score:', round(np.mean(folds_F1_score),4))\n",
        "  print('AUC:', round(np.mean(folds_AUC),4))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOfXEsTNzO7v",
        "colab_type": "text"
      },
      "source": [
        "# Main\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFangIGCDjl3",
        "colab_type": "text"
      },
      "source": [
        "## Load & clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiiHQYkyDb2V",
        "colab_type": "code",
        "outputId": "4ec0aa90-089b-4da7-c2a2-812bf0e02b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "benign_path = '../Cuckoo_Parser/Parsed_Data/win10/benign_parquet_updated'\n",
        "malware_path = '../Cuckoo_Parser/Parsed_Data/win10/malware_parquet_updated'\n",
        "\n",
        "# all_data = load_raw_parquets(benign_path, malware_path)\n",
        "# all_data.to_pickle('data_for_LSTM.pkl')\n",
        "all_data = pd.read_pickle('/content/drive/My Drive/Thesis/RNN_LSTM/data_for_LSTM.pkl')\n",
        "\n",
        "# Clean data (remove short sequence & remove duplications)\n",
        "sequence_MIN_length = 15 # (Pascano, 2015)\n",
        "all_data = data_cleaning(sequence_MIN_length,all_data)\n",
        "\n",
        "# use file from other experiments\n",
        "dataset_name = '1_Balanced_Frequencies_first1000sec_minAPI_15_minRunTime_0_withYara_No.csv'\n",
        "folder_path = '/content/drive/My Drive/Thesis/RNN_LSTM/balaned_datasets'\n",
        "full_path = '{}/{}'.format(folder_path,dataset_name)\n",
        "all_data = use_spesific_files(full_path,all_data)\n",
        "\n",
        "API_corpus = create_API_corpus(all_data)\n",
        "\n",
        "all_data_distribuation = get_classes_distribution_df(all_data)\n",
        "print(all_data_distribuation)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove files with short sequence\n",
            "files before: 7156\n",
            "files after: 6166\n",
            "files before: 6166\n",
            "files after: 4531\n",
            "API_corpus: 303\n",
            "Benign:2277 (50.25%) | Malicious:2254 (49.75%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_2tygDfDebw",
        "colab_type": "text"
      },
      "source": [
        "## strat cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx-gvpMq2GQn",
        "colab_type": "code",
        "outputId": "e1b2e269-32fe-4c9d-c779-1c5962e6cb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### --- set experiment parameters --- ###\n",
        "\n",
        "# prepare data for representation model (Optional)\n",
        "LSTM_train_seq_MAX_length = 50 # (Athiwaratkun, 2017)\n",
        "LSTM_train_seq_MAX_length = 100 # (Pascanu, 2015)\n",
        "\n",
        "# LSTM learning params\n",
        "output_dim = len(API_corpus)\n",
        "input_seq_size = len(API_corpus)\n",
        "input_time_dim = None\n",
        "nb_units = 1500 # (pascanu 2015, Agrawal 2018, Athiwaratkun 2017)\n",
        "nb_units = 100 # (Zhang 2020)\n",
        "dropout = 0.1\n",
        "epochs = 5\n",
        "nb_folds = 10\n",
        "\n",
        "# Classification params\n",
        "classification_seq_MAX_length = 200 #(Agrawal 2018 , Athiwaratkun 2017)\n",
        "one_hot_encoding = True\n",
        "\n",
        "\n",
        "data_sequences = all_data['API_sequence']\n",
        "data_labels = all_data['class']\n",
        "\n",
        "\n",
        "folds_TPR, folds_FPR, folds_ACC, folds_F1_score, folds_Precision, folds_AUC = [], [], [], [], [], []\n",
        "kfold = StratifiedKFold(n_splits=nb_folds, shuffle=True, random_state=10)\n",
        "fold = 0\n",
        "for train, test in kfold.split(data_sequences, data_labels):\n",
        "  fold += 1\n",
        "\n",
        "  print(' ------------- Fold {} -------------'.format(fold))\n",
        "\n",
        "  x_train, y_train = data_sequences.iloc[train], data_labels.iloc[train]\n",
        "  x_test, y_test = data_sequences.iloc[test], data_labels.iloc[test]\n",
        "  \n",
        "  x_train = x_train.reset_index(drop=True)\n",
        "  y_train = y_train.reset_index(drop=True)\n",
        "  x_test = x_test.reset_index(drop=True)\n",
        "  y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "  ### --------------- Phase 1: Representation Learning ------------------- ##\n",
        "\n",
        "  # prepare data for LSTM training with the final label (0/1)\n",
        "  x_train_rep,y_train_rep = prepare_data_finalLabel(x_train,y_train,LSTM_train_seq_MAX_length)\n",
        "  x_test_rep, y_test_rep = prepare_data_finalLabel(x_test, y_test,LSTM_train_seq_MAX_length)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # create the LSTM model\n",
        "  LSTM_model = LSTM_finalLabel_arch_1(input_seq_size,\n",
        "                                      input_time_dim,\n",
        "                                      nb_units,\n",
        "                                      dropout)\n",
        "\n",
        "  # train model on training data\n",
        "  LSTM_model.fit(x_train_rep,y_train_rep, epochs=epochs)\n",
        "\n",
        "  \n",
        "  # mid-process evaluation of the representation learning model\n",
        "  evaluate_LSTM_finalLabel(LSTM_model,x_test_rep,y_test_rep)\n",
        "\n",
        "  # save the model\n",
        "  # model_2.save('./LSTM_models/arch_1_LSTM_finalLabel.hdf5')\n",
        "\n",
        "  ### --------------- Phase 2: Classification --------------------------- ##\n",
        "\n",
        "  # create feature vector - feature extraction\n",
        "  x_train_final, y_train_final = final_feature_vector(LSTM_model,\n",
        "                                       x_train,\n",
        "                                       y_train,\n",
        "                                       one_hot_encoding,\n",
        "                                       classification_seq_MAX_length)\n",
        "  \n",
        "  # create feature vector - feature extraction\n",
        "  x_test_final, y_test_final = final_feature_vector(LSTM_model,\n",
        "                                       x_test,\n",
        "                                       y_test,\n",
        "                                       one_hot_encoding,\n",
        "                                       classification_seq_MAX_length)\n",
        "\n",
        "  # train classifier\n",
        "  LR_classifier = LR_fit(x_train_final, y_train_final, max_iter=1000)\n",
        "\n",
        "  # predict \n",
        "  y_preds,y_proba = LR_predict(LR_classifier,x_test_final)\n",
        "\n",
        "  # evaluate classifier\n",
        "  conf_matrix = confusion_matrix(y_test_final, y_preds)\n",
        "  # calc all the relevant metrics\n",
        "  metrics = calc_metrics(conf_matrix, y_proba, y_test_final)\n",
        "  metrics_print = '\\tTPR:{}\\tFPR:{}\\tACC:{}\\tPrecision:{}\\tF1_score:{}\\tAUC:{}'.format(metrics['TPR'],\n",
        "                                                                                        metrics['FPR'],\n",
        "                                                                                        metrics['ACC'],\n",
        "                                                                                        metrics['Precision'],\n",
        "                                                                                        metrics['F1_score'],\n",
        "                                                                                        metrics['AUC'])\n",
        "\n",
        "  print('[Fold {}/{}] -\\t{}:\\t{} '.format(fold, nb_folds, 'LR', metrics_print))\n",
        "  folds_TPR.append(metrics['TPR'])\n",
        "  folds_FPR.append(metrics['FPR'])\n",
        "  folds_ACC.append(metrics['ACC'])\n",
        "  folds_Precision.append(metrics['Precision'])\n",
        "  folds_F1_score.append(metrics['F1_score'])\n",
        "  folds_AUC.append(metrics['AUC'])\n",
        "\n",
        "\n",
        "\n",
        "print_final_results(y_train_final,folds_TPR,folds_FPR,folds_ACC,folds_Precision,folds_F1_score,folds_AUC)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ------------- Fold 1 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4077/4077 [==============================] - 46s 11ms/step - loss: 0.4876 - accuracy: 0.7797\n",
            "Epoch 2/5\n",
            "4077/4077 [==============================] - 44s 11ms/step - loss: 0.3887 - accuracy: 0.8430\n",
            "Epoch 3/5\n",
            "4077/4077 [==============================] - 44s 11ms/step - loss: 0.3405 - accuracy: 0.8680\n",
            "Epoch 4/5\n",
            "4077/4077 [==============================] - 44s 11ms/step - loss: 0.3305 - accuracy: 0.8693\n",
            "Epoch 5/5\n",
            "4077/4077 [==============================] - 44s 11ms/step - loss: 0.3063 - accuracy: 0.8837\n",
            "LSTM representation accuracy: 0.8767\n",
            "[Fold 1/10] -\tLR:\t\tTPR:0.87\tFPR:0.09\tACC:0.89\tPrecision:0.91\tF1_score:0.89\tAUC:0.9555 \n",
            " ------------- Fold 2 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.4785 - accuracy: 0.7916\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3660 - accuracy: 0.8556\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3384 - accuracy: 0.8678\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3172 - accuracy: 0.8811\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3129 - accuracy: 0.8825\n",
            "LSTM representation accuracy: 0.9139\n",
            "[Fold 2/10] -\tLR:\t\tTPR:0.92\tFPR:0.09\tACC:0.91\tPrecision:0.91\tF1_score:0.91\tAUC:0.9499 \n",
            " ------------- Fold 3 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.4878 - accuracy: 0.7869\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3666 - accuracy: 0.8575\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3434 - accuracy: 0.8722\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3140 - accuracy: 0.8821\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3056 - accuracy: 0.8838\n",
            "LSTM representation accuracy: 0.9051\n",
            "[Fold 3/10] -\tLR:\t\tTPR:0.91\tFPR:0.07\tACC:0.92\tPrecision:0.93\tF1_score:0.92\tAUC:0.9668 \n",
            " ------------- Fold 4 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.4785 - accuracy: 0.7901\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 43s 11ms/step - loss: 0.3599 - accuracy: 0.8592\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.4313 - accuracy: 0.8232\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 43s 11ms/step - loss: 0.3857 - accuracy: 0.8489\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 43s 11ms/step - loss: 0.3757 - accuracy: 0.8592\n",
            "LSTM representation accuracy: 0.8653\n",
            "[Fold 4/10] -\tLR:\t\tTPR:0.85\tFPR:0.07\tACC:0.89\tPrecision:0.92\tF1_score:0.89\tAUC:0.9512 \n",
            " ------------- Fold 5 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.4793 - accuracy: 0.7818\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3845 - accuracy: 0.8485\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3463 - accuracy: 0.8676\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3097 - accuracy: 0.8813\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3102 - accuracy: 0.8811\n",
            "LSTM representation accuracy: 0.9095\n",
            "[Fold 5/10] -\tLR:\t\tTPR:0.88\tFPR:0.06\tACC:0.91\tPrecision:0.93\tF1_score:0.91\tAUC:0.9573 \n",
            " ------------- Fold 6 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.4885 - accuracy: 0.7898\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3748 - accuracy: 0.8524\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 44s 11ms/step - loss: 0.3381 - accuracy: 0.8720\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3631 - accuracy: 0.8499\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3210 - accuracy: 0.8752\n",
            "LSTM representation accuracy: 0.8234\n",
            "[Fold 6/10] -\tLR:\t\tTPR:0.87\tFPR:0.09\tACC:0.89\tPrecision:0.91\tF1_score:0.89\tAUC:0.9388 \n",
            " ------------- Fold 7 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.4867 - accuracy: 0.7813\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3768 - accuracy: 0.8514\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3680 - accuracy: 0.8661\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.5111 - accuracy: 0.7597\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3261 - accuracy: 0.8767\n",
            "LSTM representation accuracy: 0.8808\n",
            "[Fold 7/10] -\tLR:\t\tTPR:0.86\tFPR:0.09\tACC:0.89\tPrecision:0.9\tF1_score:0.88\tAUC:0.9371 \n",
            " ------------- Fold 8 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.4872 - accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3741 - accuracy: 0.8568\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 47s 11ms/step - loss: 0.3638 - accuracy: 0.8595\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3174 - accuracy: 0.8808\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 45s 11ms/step - loss: 0.3068 - accuracy: 0.8857\n",
            "LSTM representation accuracy: 0.9051\n",
            "[Fold 8/10] -\tLR:\t\tTPR:0.88\tFPR:0.08\tACC:0.9\tPrecision:0.91\tF1_score:0.9\tAUC:0.9522 \n",
            " ------------- Fold 9 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 47s 11ms/step - loss: 0.4842 - accuracy: 0.7955\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3664 - accuracy: 0.8570\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3302 - accuracy: 0.8769\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 47s 11ms/step - loss: 0.3161 - accuracy: 0.8840\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3282 - accuracy: 0.8781\n",
            "LSTM representation accuracy: 0.8433\n",
            "[Fold 9/10] -\tLR:\t\tTPR:0.87\tFPR:0.07\tACC:0.9\tPrecision:0.92\tF1_score:0.9\tAUC:0.9424 \n",
            " ------------- Fold 10 -------------\n",
            "Bulding LSTM model - final Label (arch 1)\n",
            "Epoch 1/5\n",
            "4078/4078 [==============================] - 47s 11ms/step - loss: 0.4745 - accuracy: 0.7982\n",
            "Epoch 2/5\n",
            "4078/4078 [==============================] - 47s 12ms/step - loss: 0.4115 - accuracy: 0.8320\n",
            "Epoch 3/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3450 - accuracy: 0.8720\n",
            "Epoch 4/5\n",
            "4078/4078 [==============================] - 47s 11ms/step - loss: 0.3291 - accuracy: 0.8759\n",
            "Epoch 5/5\n",
            "4078/4078 [==============================] - 46s 11ms/step - loss: 0.3030 - accuracy: 0.8889\n",
            "LSTM representation accuracy: 0.8874\n",
            "[Fold 10/10] -\tLR:\t\tTPR:0.87\tFPR:0.11\tACC:0.88\tPrecision:0.88\tF1_score:0.88\tAUC:0.9439 \n",
            "\n",
            "Final Results: 4078 samples\n",
            "TPR: 0.878\n",
            "FPR: 0.082\n",
            "ACC: 0.898\n",
            "Precision: 0.912\n",
            "F1_score: 0.897\n",
            "AUC: 0.9495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJl9FW79FXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "17643e46-3599-464c-b282-05d48df58853"
      },
      "source": [
        "# save results\n",
        "\n",
        "columns = ['dataset', 'classes_distribution','analysis_time',\n",
        "           'num_of_features','model','representation_model',\n",
        "           'representation_model_conf','representation_Max_seq','classification_Max_seq','classifier','classifier_conf',\n",
        "           'TPR','FPR','ACC','Precision','F1_score','AUC']\n",
        "\n",
        "\n",
        "result_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "new_record = {\n",
        "    'dataset':dataset_name,\n",
        "    'classes_distribution':all_data_distribuation,\n",
        "    'analysis_time':1000,\n",
        "    'num_of_features':2*nb_units,\n",
        "    'model':'LSTM_finalLabel_MaxPooling_LR',\n",
        "    'representation_model':'LSTM_finalLabel',\n",
        "    'representation_model_conf':LSTM_model.get_config(),\n",
        "    'representation_Max_seq':LSTM_train_seq_MAX_length,\n",
        "    'classification_Max_seq':classification_seq_MAX_length,\n",
        "    'classifier':'LogisticRegression',\n",
        "    'classifier_conf':LR_classifier.get_params(),\n",
        "    'TPR':np.mean(folds_TPR),\n",
        "    'FPR':np.mean(folds_FPR),\n",
        "    'ACC': np.mean(folds_ACC),\n",
        "    'Precision':np.mean(folds_Precision),\n",
        "    'F1_score':np.mean(folds_F1_score),\n",
        "    'AUC':np.mean(folds_AUC)\n",
        "}\n",
        "\n",
        "result_df = result_df.append(new_record, ignore_index=True)\n",
        "result_df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>classes_distribution</th>\n",
              "      <th>analysis_time</th>\n",
              "      <th>num_of_features</th>\n",
              "      <th>model</th>\n",
              "      <th>representation_model</th>\n",
              "      <th>representation_model_conf</th>\n",
              "      <th>representation_Max_seq</th>\n",
              "      <th>classification_Max_seq</th>\n",
              "      <th>classifier</th>\n",
              "      <th>classifier_conf</th>\n",
              "      <th>TPR</th>\n",
              "      <th>FPR</th>\n",
              "      <th>ACC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1_score</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_Balanced_Frequencies_first1000sec_minAPI_15_...</td>\n",
              "      <td>Benign:2277 (50.25%) | Malicious:2254 (49.75%)</td>\n",
              "      <td>1000</td>\n",
              "      <td>200</td>\n",
              "      <td>LSTM_finalLabel_MaxPooling_LR</td>\n",
              "      <td>LSTM_finalLabel</td>\n",
              "      <td>{'name': 'sequential_46', 'layers': [{'class_n...</td>\n",
              "      <td>100</td>\n",
              "      <td>200</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.912</td>\n",
              "      <td>0.897</td>\n",
              "      <td>0.94951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             dataset  ...      AUC\n",
              "0  1_Balanced_Frequencies_first1000sec_minAPI_15_...  ...  0.94951\n",
              "\n",
              "[1 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx9ZSmqiqUAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df.to_csv('/content/drive/My Drive/Thesis/RNN_LSTM/LSTM_finalLabel_MaxPooling_LR_level_0_results')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}